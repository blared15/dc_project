{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, time, shutil\n",
    "os.chdir('/Users/raeniellesunga/Desktop')\n",
    "columns = shutil.get_terminal_size().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                       ____        _             _                _           _                                                                           \n",
      "                                                                      |  _ \\  __ _| |_ __ _     / \\   _ __   __ _| |_   _ ___(_)___                                                                       \n",
      "                                                                      | | | |/ _` | __/ _` |   / _ \\ | '_ \\ / _` | | | | / __| / __|                                                                      \n",
      "                                                                      | |_| | (_| | || (_| |  / ___ \\| | | | (_| | | |_| \\__ \\ \\__ \\                                                                      \n",
      "                                                                      |____/ \\__,_|\\__\\__,_| /_/   \\_\\_| |_|\\__,_|_|\\__, |___/_|___/                                                                      \n",
      "                                                                                                                    |___/                                                                                 \n",
      "**********************************************************************************************************************************************************************************************************\n",
      "                                                       This script is used to compares 2 columns from 2 spreadsheets and also check for duplicates                                                        \n",
      "                                                                                 This script only analyses worbook files                                                                                  \n",
      "                                                              If you have any questions you can reach out to Raeniele @ rsunga@netsuite.com                                                               \n",
      "**********************************************************************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "title = [\"  ____        _             _                _           _     \",\n",
    "\" |  _ \\  __ _| |_ __ _     / \\   _ __   __ _| |_   _ ___(_)___ \",\n",
    "\" | | | |/ _` | __/ _` |   / _ \\ | '_ \\ / _` | | | | / __| / __|\",\n",
    "\" | |_| | (_| | || (_| |  / ___ \\| | | | (_| | | |_| \\__ \\ \\__ \\ \",\n",
    "\" |____/ \\__,_|\\__\\__,_| /_/   \\_\\_| |_|\\__,_|_|\\__, |___/_|___/\",\n",
    "\"                                        |___/    \"]\n",
    "\n",
    "for x in title:\n",
    "    print(x.center(columns))\n",
    "print(''.center(columns,'*'))\n",
    "print('This script is used to compares 2 columns from 2 spreadsheets and also check for duplicates'.center(columns))\n",
    "print('This script only analyses worbook files'.center(columns))\n",
    "print('If you have any questions you can reach out to Raeniele @ rsunga@netsuite.com'.center(columns))\n",
    "print(''.center(columns,'*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(prompt):\n",
    "    #Get file name\n",
    "    file_name = input(prompt)\n",
    "    #only asking for .xlsx to make script less complicated\n",
    "    \n",
    "    #use os module to check for file\n",
    "    check = os.path.isfile(file_name)\n",
    "    #if file is not there, ask again\n",
    "    if check == False:\n",
    "        while check == False:\n",
    "            file_name = input(prompt)\n",
    "            \n",
    "            #check again if the file is there after asking user to enter name\n",
    "            check = os.path.isfile(file_name)\n",
    "            print(f\"{file_name} found: \" + str(check)) \n",
    "            #return the file_name out of the function so we can store it in a variable\n",
    "            return file_name\n",
    "    else:\n",
    "        #if file is there just return the file_name\n",
    "        print(f\"{file_name} found: \" + str(check)) \n",
    "        return file_name\n",
    "\n",
    "def get_column(data):\n",
    "    #showing the available columns to choose from\n",
    "    print(f\"Available columns:\\n\", data.columns.values)\n",
    "    column = input(\"\\n\\nSelect the column you want to use:\")\n",
    "    check = column in data.columns.values\n",
    "    if check == False:\n",
    "        while check == False:\n",
    "            print(\"Column invald. Try again\")\n",
    "            print(\"Available columns:\\n\", data.columns.values)\n",
    "            column = input(\"\\n\\nSelect the column you want to use:\")\n",
    "            check = column in data.columns.values\n",
    "    else:\n",
    "        return column\n",
    "            \n",
    "def check_duplicate(data,column):\n",
    "    #getting duplicates from the column specified\n",
    "    duplicate = data[data.duplicated(subset=[column])]\n",
    "    print(f'This column has {len(duplicate)} duplicated item\\n')\n",
    "    # \n",
    "    if len(duplicate) > 1:\n",
    "        cleaned_data = data[~data.duplicated(subset=[column])]\n",
    "        print(duplicate)\n",
    "        print('Cleaning data')\n",
    "        return cleaned_data,duplicate\n",
    "    else:\n",
    "        #assigning default values to prevent error when assigning to variables\n",
    "        cleaned_data = data[~data.duplicated(subset=[column])]\n",
    "        duplicate = 'none'\n",
    "        return cleaned_data,duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file name (source) that you want to check including file extension ex: media_sanitation.xls:  Media Sanitation Form URO3220 Tukwila QA.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Sanitation Form URO3220 Tukwila QA.xlsx found: True\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file name that you want to check Media Sanitation Form URO3220 Tukwila QA.xlsx against including file extension ex: SE4_decom_list.xlsx:  FY20Q3_DRIVE (1).xls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FY20Q3_DRIVE (1).xls found: True\n"
     ]
    }
   ],
   "source": [
    "#Assigning file_name to 2 variables\n",
    "file_1 = get_file(\"Enter the file name (source) that you want to check including file extension ex: media_sanitation.xls: \")\n",
    "file_2 = get_file(f\"Enter the file name that you want to check {file_1} against including file extension ex: SE4_decom_list.xlsx: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Spreadsheets to dataframe\n"
     ]
    }
   ],
   "source": [
    "#get the spreadsheet and convert it to Pandas dataframe\n",
    "print('Converting Spreadsheets to dataframe')\n",
    "data_1 = pd.read_excel(file_1)\n",
    "data_2 = pd.read_excel(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Sanitation Form URO3220 Tukwila QA.xlsx contains 1557 rows\n",
      "\n",
      "Available columns:\n",
      " ['  Device  Manufacturer'\n",
      " ' Device\\nModel Number                               '\n",
      " '  Device\\n Part Number' 'Device Serial Number' 'Oracle Base \\nPN'\n",
      " 'Oracle Base\\n SN'\n",
      " 'Media Type \\n(i.e., magnetic, flash memory, hybrid, etc.)  '\n",
      " 'Media Source \\n(i.e., user or computer the media came from)'\n",
      " ' Device \\nSN' 'Sanitization Description \\n(i.e., Clear, Purge, Destroy)'\n",
      " 'Method Used                           (i.e., degauss, overwrite, block erase, crypto erase,  Crush, Shred, etc.)'\n",
      " 'Tool Used \\n(including version)'\n",
      " 'Verification Method (i.e., full, quick sampling, etc.)'\n",
      " 'Post-Sanitization Confidentiality Categorization (optional)'\n",
      " 'Post-Sanitization Destination         \\n     (if known)'\n",
      " 'Name of Supplier  Person' 'Position/Title \\nof Person' 'Date' 'Location'\n",
      " 'Phone or Other Contact Information' 'Signature'\n",
      " 'NAME OF ORACLE PERSONNEL AT ORIGIN-SITE WHO WITNESSES 100% OFTHE SANITATION AND DESTRUCTION ACTVITIES']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select the column you want to use: Device Serial Number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FY20Q3_DRIVE (1).xls contains 1453 rows\n",
      "Available columns:\n",
      " ['sn' 'type' 'host' 'asset']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Select the column you want to use: sn\n"
     ]
    }
   ],
   "source": [
    "#Getting column names to use for comparison and assigning them to variables\n",
    "\n",
    "column_1 = get_column(data_1)\n",
    "print(f\"{file_2} contains {len(data_2)} rows\")\n",
    "column_2 = get_column(data_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media Sanitation Form URO3220 Tukwila QA.xlsx contains 1557 rows\n",
      "\n",
      "FY20Q3_DRIVE (1).xls contains 1453 rows\n",
      "\n",
      "Checking column \"Device Serial Number\" in Media Sanitation Form URO3220 Tukwila QA.xlsx for duplicated data\n",
      "\n",
      "This column has 0 duplicated item\n",
      "\n",
      "Checking sn in FY20Q3_DRIVE (1).xls for duplicated data\n",
      "\n",
      "This column has 2 duplicated item\n",
      "\n",
      "                sn           type                          host    asset\n",
      "786       S3L2HY4K  SAS 1.2TB 10K  kafka20004.sea.netledger.com  4000807\n",
      "1373  1549113E0CF4      240GB SSD  db018.prod.sea.netledger.com  4000644\n",
      "Cleaning data\n"
     ]
    }
   ],
   "source": [
    "print(f\"{file_1} contains {len(data_1)} rows\\n\")\n",
    "print(f\"{file_2} contains {len(data_2)} rows\")\n",
    "print(f'\\nChecking column \"{column_1}\" in {file_1} for duplicated data\\n')\n",
    "#assigning data to variables\n",
    "cleaned_data_1,data_1_duplicate = check_duplicate(data_1,column_1)\n",
    "print(f'Checking {column_2} in {file_2} for duplicated data\\n')\n",
    "cleaned_data_2,data_2_duplicate = check_duplicate(data_2,column_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if the data in the \"sn\" column on FY20Q3_DRIVE (1).xls exist in \"Device Serial Number\" column on Media Sanitation Form URO3220 Tukwila QA.xlsx exist\n",
      "Z4D2KQ5Z not in file_1\n",
      "added\n",
      "JEH6AAWN not in file_1\n",
      "added\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>type</th>\n",
       "      <th>host</th>\n",
       "      <th>asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Z4D2KQ5Z</td>\n",
       "      <td>6TB 7.2K SAS</td>\n",
       "      <td>gfs109.prod.sea.netledger.com</td>\n",
       "      <td>4000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>JEH6AAWN</td>\n",
       "      <td>SAS 10TB 7.2K</td>\n",
       "      <td>gfs417.prod.sea.netledger.com</td>\n",
       "      <td>4003811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sn           type                           host    asset\n",
       "171  Z4D2KQ5Z   6TB 7.2K SAS  gfs109.prod.sea.netledger.com  4000634\n",
       "211  JEH6AAWN  SAS 10TB 7.2K  gfs417.prod.sea.netledger.com  4003811"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Checking if the data in the \"{column_2}\" column on {file_2} exist in \"{column_1}\" column on {file_1} exist')\n",
    "match_index = pd.DataFrame()\n",
    "unmatch_index = pd.DataFrame()\n",
    "for x in data_2[column_2]:\n",
    "    if x in data_1.values:\n",
    "        match_index = match_index.append(data_1.loc[data_1[column_1]==x])\n",
    "\n",
    "    else:\n",
    "        print(x,\"not in file_1\")\n",
    "        unmatch_index = unmatch_index.append(data_2.loc[data_2[column_2]==x]) \n",
    "        print('added')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sn</th>\n",
       "      <th>type</th>\n",
       "      <th>host</th>\n",
       "      <th>asset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Z4D2KQ5Z</td>\n",
       "      <td>6TB 7.2K SAS</td>\n",
       "      <td>gfs109.prod.sea.netledger.com</td>\n",
       "      <td>4000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>JEH6AAWN</td>\n",
       "      <td>SAS 10TB 7.2K</td>\n",
       "      <td>gfs417.prod.sea.netledger.com</td>\n",
       "      <td>4003811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sn           type                           host    asset\n",
       "171  Z4D2KQ5Z   6TB 7.2K SAS  gfs109.prod.sea.netledger.com  4000634\n",
       "211  JEH6AAWN  SAS 10TB 7.2K  gfs417.prod.sea.netledger.com  4003811"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmatch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ty = [\n",
    "\",--------.,--.                     ,--.                                \",\n",
    "\"'--.  .--'|  ,---.  ,--,--.,--,--, |  |,-.     ,--. ,--.,---. ,--.,--. \",\n",
    "\"   |  |   |  .-.  |' ,-.  ||      \\|     /      \\  '  /| .-. ||  ||  | \",\n",
    "\"   |  |   |  | |  |\\ '-'  ||  ||  ||  \\  \\       \\   ' ' '-' ''  ''  ' \",\n",
    "\"   `--'   `--' `--' `--`--'`--''--'`--'`--'    .-'  /   `---'  `----'  \",\n",
    "\"                                                  `---'                       \"             ]                                                       \n",
    "\n",
    "match = [\n",
    " \"_  ___   ___    _  __                   _       _    \", \n",
    "\"/ |/ _ \\ / _ \\  (_)/ /   _ __ ___   __ _| |_ ___| |__  \",\n",
    "\"| | | | | | | |   / /   | '_ ` _ \\ / _` | __/ __| '_ \\ \",\n",
    "\"| | |_| | |_| |  / /_   | | | | | | (_| | || (__| | | |\",\n",
    "\"|_|\\___/ \\___/  /_/(_)  |_| |_| |_|\\__,_|\\__\\___|_| |_|\"\n",
    "                                                       \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ,--------.,--.                     ,--.                                                                                                  \n",
      "                                                                 '--.  .--'|  ,---.  ,--,--.,--,--, |  |,-.     ,--. ,--.,---. ,--.,--.                                                                   \n",
      "                                                                    |  |   |  .-.  |' ,-.  ||      \\|     /      \\  '  /| .-. ||  ||  |                                                                   \n",
      "                                                                    |  |   |  | |  |\\ '-'  ||  ||  ||  \\  \\       \\   ' ' '-' ''  ''  '                                                                   \n",
      "                                                                    `--'   `--' `--' `--`--'`--''--'`--'`--'    .-'  /   `---'  `----'                                                                    \n",
      "                                                                                                                `---'                                                                                     \n",
      "**********************************************************************************************************************************************************************************************************\n",
      "                                                                                     Found 1451 match and 2 unmatch                                                                                       \n",
      "                                                                                File \"Analyzed Data.xlsx\" will be exported                                                                                \n",
      "**********************************************************************************************************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "if len(unmatch_index) !=0:\n",
    "    for x in ty:\n",
    "        print(x.center(columns))\n",
    "    print(''.center(columns,'*'))\n",
    "    print(f'Found {len(match_index)} match and {len(unmatch_index)} unmatch '.center(columns))\n",
    "    print('File \"Analyzed Data.xlsx\" will be exported'.center(columns))\n",
    "    print(''.center(columns,'*'))\n",
    "    with pd.ExcelWriter('Analyzed Data.xlsx') as writer:\n",
    "        data_2.to_excel(writer,sheet_name=\"Source\",index=False)\n",
    "        match_index.to_excel(writer,sheet_name=\"Matched Data\",index=False)      \n",
    "        unmatch_index.to_excel(writer,sheet_name=\"Unmatched Data\",index=False)     \n",
    "else:\n",
    "    for x in match:\n",
    "        print(x.center(columns))\n",
    "    print('\\n\\n')\n",
    "    for x in ty:\n",
    "        print(x.center(columns))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
